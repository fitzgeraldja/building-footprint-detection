{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/fitzgeraldja/building-footprint-detection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/building-footprint-detection/ttAugment-0.4.1\n",
    "%pip install -e . \n",
    "%pip install --no-cache-dir building-footprint-segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "from building_footprint_segmentation.seg.binary.models import DLinkNet34\n",
    "from building_footprint_segmentation.helpers.normalizer import min_max_image_net\n",
    "from building_footprint_segmentation.utils.py_network import (\n",
    "    to_input_image_tensor,\n",
    "    add_extra_dimension,\n",
    "    convert_tensor_to_numpy,\n",
    "    load_parallel_model,\n",
    "    adjust_model\n",
    ")\n",
    "from torch.utils import model_zoo\n",
    "\n",
    "from tt_augment.augment import generate_seg_augmenters\n",
    "\n",
    "from scipy.ndimage import binary_dilation\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "\n",
    "%matplotlib inline \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = DLinkNet34()\n",
    "    state_dict = model_zoo.load_url(r\"https://github.com/fuzailpalnak/building-footprint-segmentation/releases/download/v0.2.3/DlinkNet.zip\", progress=True, map_location=\"cpu\")\n",
    "    state_dict = adjust_model(state_dict[\"model\"])\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMATION_TO_APPLY = [\n",
    "  {\"name\": \"Mirror\", \"crop_to_dimension\": (128, 128)},\n",
    "  {\"name\": \"CropScale\", \"crop_to_dimension\": (128, 128)},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_mask_to_geojson(\n",
    "    msk: np.ndarray, \n",
    "    out_fname: str,\n",
    "    dilation_iters: int | None = 2, \n",
    "    save_dir: str | Path = \"/content/building-footprint-detection/pred_masks\",\n",
    "    plot: bool = True\n",
    "):\n",
    "  save_dir = Path(save_dir)\n",
    "  save_dir.mkdir(exist_ok = True)\n",
    "  # apply binary dilation to mask to merge nearby patches\n",
    "  if dilation_iters is not None:\n",
    "    msk = binary_dilation(msk, iterations=dilation_iters)\n",
    "  \n",
    "  # get minimal boundaries of mask patches\n",
    "  contours, hierarchy = cv2.findContours((msk * 255).astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  # convert hull arrays to polygons so suitable format for conversion\n",
    "  sq_contours = map(np.squeeze, contours)  # removing redundant dimensions\n",
    "  polygons = map(Polygon, sq_contours)  # converting to Polygons\n",
    "  multipolygon = MultiPolygon(polygons)  # putting it all together in a MultiPolygon\n",
    "\n",
    "  # convert to gdf so can subsequently convert to geojson\n",
    "  gdf = gpd.GeoDataFrame(index=[0], geometry=[multipolygon])\n",
    "  \n",
    "  if plot:\n",
    "    # show the dilated mask\n",
    "    gdf.plot()\n",
    "    plt.show()\n",
    "  \n",
    "  gdf.to_file(save_dir / out_fname, driver='GeoJSON')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "\n",
    "data_dir = Path(\"/content/building-footprint-detection/data\")\n",
    "img_pths = data_dir.glob(\"*\")\n",
    "save_dir = data_dir.parent / \"pred_masks\"\n",
    "# n_imgs = len(list(img_pths))\n",
    "\n",
    "for img_pth in img_pths:\n",
    "    # load og img\n",
    "    print(f\"running img {img_pth.name}\")\n",
    "    original_image = cv2.imread(str(img_pth))\n",
    "    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    # plt.imshow(original_image, interpolation='nearest')\n",
    "    # plt.show()\n",
    "    print(\"image loaded\")\n",
    "\n",
    "    # prep for modelling\n",
    "    image = min_max_image_net(img=original_image)\n",
    "    image = np.expand_dims(image, 0)\n",
    "\n",
    "    h, w, _ = original_image.shape\n",
    "    number_of_output_channels = 1\n",
    "\n",
    "    # init test-time transforms\n",
    "    tta_alt = generate_seg_augmenters(\n",
    "                image=image,\n",
    "                window_size=(256, 256),\n",
    "                output_dimension=(1, h, w, number_of_output_channels),\n",
    "                transformation_to_apply=TRANSFORMATION_TO_APPLY,\n",
    "            )\n",
    "\n",
    "    print(\"applying transforms to each fragment and running model...\")\n",
    "    # apply transforms to each fragment of img\n",
    "    for iterator, transformation in enumerate(tta_alt):\n",
    "        for augmented_fragment in transformation.transform_fragment():\n",
    "            tensor_image = to_input_image_tensor(augmented_fragment).swapaxes(0, 1)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Perform prediction\n",
    "                prediction = model(tensor_image)\n",
    "                prediction = prediction.sigmoid()\n",
    "                \n",
    "                prediction_binary = convert_tensor_to_numpy(prediction.swapaxes(-1, 1))\n",
    "                # need to correct for original swap - old example ntb failed to do\n",
    "                # so and was clearly incorrect\n",
    "                transformation.restore_fragment(prediction_binary.swapaxes(1, 2)) \n",
    "    # collect results (mean by default)\n",
    "    tta_alt.merge()\n",
    "    output = tta_alt.tta_output()\n",
    "\n",
    "    # plot og img\n",
    "    original_image = cv2.imread(str(img_pth))\n",
    "    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(original_image, interpolation='nearest')\n",
    "    # plt.show()\n",
    "\n",
    "    # get binary mask from preds\n",
    "    msk = output[0] > np.median(output[0]) + 2*np.std(output[0])\n",
    "    # msk[msk==0] = np.nan\n",
    "    masked_array = np.ma.array(msk, mask=~msk)\n",
    "\n",
    "    # overlay on og img and show\n",
    "    plt.imshow(masked_array, alpha=0.5, cmap='spring', interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "    # save to file w some dilation to merge nearby patches\n",
    "    binary_mask_to_geojson(\n",
    "        msk, \n",
    "        out_fname=f\"{img_pth.stem}.geojson\",\n",
    "        dilation_iters = 2, \n",
    "        save_dir = save_dir,\n",
    "        plot= False\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
