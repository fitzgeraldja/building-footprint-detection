{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/ttAugment/\n",
    "%pip install -e . \n",
    "%pip install --no-cache-dir building-footprint-segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from building_footprint_segmentation.seg.binary.models import DLinkNet34\n",
    "from building_footprint_segmentation.helpers.normalizer import min_max_image_net\n",
    "from building_footprint_segmentation.utils.py_network import (\n",
    "    to_input_image_tensor,\n",
    "    add_extra_dimension,\n",
    "    convert_tensor_to_numpy,\n",
    "    load_parallel_model,\n",
    "    adjust_model\n",
    ")\n",
    "from torch.utils import model_zoo\n",
    "\n",
    "from tt_augment.augment import generate_seg_augmenters\n",
    "\n",
    "%matplotlib inline \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = DLinkNet34()\n",
    "    state_dict = model_zoo.load_url(r\"https://github.com/fuzailpalnak/building-footprint-segmentation/releases/download/v0.2.3/DlinkNet.zip\", progress=True, map_location=\"cpu\")\n",
    "    state_dict = adjust_model(state_dict[\"model\"])\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMATION_TO_APPLY = [\n",
    "  {\"name\": \"Mirror\", \"crop_to_dimension\": (128, 128)},\n",
    "  {\"name\": \"CropScale\", \"crop_to_dimension\": (128, 128)},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "\n",
    "img_pths = Path(\"/content/test_imgs\").glob(\"*\")\n",
    "# n_imgs = len(list(img_pths))\n",
    "\n",
    "for img_pth in img_pths:\n",
    "    # load og img\n",
    "    print(f\"running img {img_pth.name}\")\n",
    "    original_image = cv2.imread(str(img_pth))\n",
    "    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    # plt.imshow(original_image, interpolation='nearest')\n",
    "    # plt.show()\n",
    "    print(\"image loaded\")\n",
    "\n",
    "    # prep for modelling\n",
    "    image = min_max_image_net(img=original_image)\n",
    "    image = np.expand_dims(image, 0)\n",
    "\n",
    "    h, w, _ = original_image.shape\n",
    "    number_of_output_channels = 1\n",
    "\n",
    "    # init test-time transforms\n",
    "    tta_alt = generate_seg_augmenters(\n",
    "                image=image,\n",
    "                window_size=(256, 256),\n",
    "                output_dimension=(1, h, w, number_of_output_channels),\n",
    "                transformation_to_apply=TRANSFORMATION_TO_APPLY,\n",
    "            )\n",
    "\n",
    "    print(\"applying transforms to each fragment and running model...\")\n",
    "    # apply transforms to each fragment of img\n",
    "    for iterator, transformation in enumerate(tta_alt):\n",
    "        for augmented_fragment in transformation.transform_fragment():\n",
    "            tensor_image = to_input_image_tensor(augmented_fragment).swapaxes(0, 1)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Perform prediction\n",
    "                prediction = model(tensor_image)\n",
    "                prediction = prediction.sigmoid()\n",
    "                \n",
    "                prediction_binary = convert_tensor_to_numpy(prediction.swapaxes(-1, 1))\n",
    "                # need to correct for original swap - old example ntb failed to do\n",
    "                # so and was clearly incorrect\n",
    "                transformation.restore_fragment(prediction_binary.swapaxes(1, 2)) \n",
    "    # collect results (mean by default)\n",
    "    tta_alt.merge()\n",
    "    output = tta_alt.tta_output()\n",
    "\n",
    "    # plot og img\n",
    "    original_image = cv2.imread(str(img_pth))\n",
    "    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(original_image, interpolation='nearest')\n",
    "    # plt.show()\n",
    "\n",
    "    # get binary mask from preds\n",
    "    msk = output[0] > np.median(output[0]) + 2*np.std(output[0])\n",
    "    # msk[msk==0] = np.nan\n",
    "    masked_array = np.ma.array(msk, mask=~msk)\n",
    "\n",
    "    # overlay on og img and show\n",
    "    plt.imshow(masked_array, alpha=0.5, cmap='spring', interpolation='nearest')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
